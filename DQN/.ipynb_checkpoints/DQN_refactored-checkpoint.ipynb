{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bc1101-c8fe-4c50-ab4a-5b0ff40768b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import random\n",
    "import string\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1971c3-d1f4-419b-8bf8-1566f8a21e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup\n",
    "env = gym.make('CarRacing-v2', continuous=False)\n",
    "print(\"Observation space:\", env.observation_space)\n",
    "print(\"Action space:\", env.action_space)\n",
    "\n",
    "s, info = env.reset()\n",
    "print(s.shape)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(s)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a970a7-15c4-4be8-8b60-058f73f6e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No-op action animation\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "frames = []\n",
    "for i in range(50):\n",
    "    s, r, terminated, truncated, info = env.step(0)  # 0th action is the no_op action\n",
    "    frames.append(s)\n",
    "\n",
    "# Create animation\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "plt.axis('off')\n",
    "im = plt.imshow(frames[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a604d29a-8928-4d55-9993-148d6b7e3dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate(i):\n",
    "    im.set_array(frames[i])\n",
    "    return im,\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, frames=len(frames))\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6bb592-cdd2-47b5-beed-1646af8fb1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def preprocess(img):\n",
    "    img = img[:84, 6:90]  # Car Racing v2 specific cropping\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507b0f0e-8173-4b7f-b68d-06b95c1a150a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageEnv Wrapper\n",
    "class ImageEnv(gym.Wrapper):\n",
    "    def __init__(self, env, skip_frames=4, stack_frames=4, initial_no_op=50, **kwargs):\n",
    "        super(ImageEnv, self).__init__(env, **kwargs)\n",
    "        self.initial_no_op = initial_no_op\n",
    "        self.skip_frames = skip_frames\n",
    "        self.stack_frames = stack_frames\n",
    "\n",
    "    def reset(self):\n",
    "        s, info = self.env.reset()\n",
    "        for i in range(self.initial_no_op):\n",
    "            s, r, terminated, truncated, info = self.env.step(0)\n",
    "        s = preprocess(s)\n",
    "        self.stacked_state = np.tile(s, (self.stack_frames, 1, 1))\n",
    "        return self.stacked_state, info\n",
    "\n",
    "    def step(self, action):\n",
    "        reward = 0\n",
    "        for _ in range(self.skip_frames):\n",
    "            s, r, terminated, truncated, info = self.env.step(action)\n",
    "            reward += r\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "        s = preprocess(s)\n",
    "        self.stacked_state = np.concatenate((self.stacked_state[1:], s[np.newaxis]), axis=0)\n",
    "        return self.stacked_state, reward, terminated, truncated, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c736eba-93f9-4ccb-95a3-17f2c86280ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CarRacing-v2', continuous=False)\n",
    "env = ImageEnv(env)\n",
    "\n",
    "s, _ = env.reset()\n",
    "print(\"The shape of an observation:\", s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ef8eb0-0229-4db4-85aa-ba78e038428d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "for i in range(4):\n",
    "    axes[i].imshow(s[i], cmap='gray')\n",
    "    axes[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30955b8b-f616-4e7a-9cb2-72ba312281ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    s, r, terminated, truncated, info = env.step(3)  # 3rd action is gas action\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "for i in range(4):\n",
    "    axes[i].imshow(s[i], cmap='gray')\n",
    "    axes[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1990fdc-4d42-4756-868c-0aa6f33f520f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQN Network\n",
    "class CNNActionValue(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, activation=F.relu):\n",
    "        super(CNNActionValue, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(state_dim, 16, kernel_size=8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=4, stride=2)\n",
    "        self.in_features = 32 * 9 * 9\n",
    "        self.fc1 = nn.Linear(self.in_features, 256)\n",
    "        self.fc2 = nn.Linear(256, action_dim)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.conv1(x))\n",
    "        x = self.activation(self.conv2(x))\n",
    "        x = x.view(-1, self.in_features)\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135b5e80-82c0-463b-b116-56463250d968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replay Buffer\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, state_dim, action_dim, max_size=int(1e5)):\n",
    "        self.s = np.zeros((max_size, *state_dim), dtype=np.float32)\n",
    "        self.a = np.zeros((max_size, *action_dim), dtype=np.int64)\n",
    "        self.r = np.zeros((max_size, 1), dtype=np.float32)\n",
    "        self.s_prime = np.zeros((max_size, *state_dim), dtype=np.float32)\n",
    "        self.terminated = np.zeros((max_size, 1), dtype=np.float32)\n",
    "\n",
    "        self.ptr = 0\n",
    "        self.size = 0\n",
    "        self.max_size = max_size\n",
    "\n",
    "    def update(self, s, a, r, s_prime, terminated):\n",
    "        self.s[self.ptr] = s\n",
    "        self.a[self.ptr] = a\n",
    "        self.r[self.ptr] = r\n",
    "        self.s_prime[self.ptr] = s_prime\n",
    "        self.terminated[self.ptr] = terminated\n",
    "\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        ind = np.random.randint(0, self.size, batch_size)\n",
    "        return (torch.FloatTensor(self.s[ind]), torch.FloatTensor(self.a[ind]),\n",
    "                torch.FloatTensor(self.r[ind]), torch.FloatTensor(self.s_prime[ind]),\n",
    "                torch.FloatTensor(self.terminated[ind]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e248c088-aac4-488c-8a94-c68dd7a76d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQN Agent\n",
    "class DQN:\n",
    "    def __init__(self, state_dim, action_dim, lr=0.00025, epsilon=1.0, epsilon_min=0.1, gamma=0.99,\n",
    "                 batch_size=32, warmup_steps=5000, buffer_size=int(1e5), target_update_interval=10000):\n",
    "\n",
    "        self.action_dim = action_dim\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.gamma = gamma\n",
    "        self.batch_size = batch_size\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.target_update_interval = target_update_interval\n",
    "\n",
    "        self.network = CNNActionValue(state_dim[0], action_dim)\n",
    "        self.target_network = CNNActionValue(state_dim[0], action_dim)\n",
    "        self.target_network.load_state_dict(self.network.state_dict())\n",
    "        self.optimizer = torch.optim.RMSprop(self.network.parameters(), lr)\n",
    "\n",
    "        self.buffer = ReplayBuffer(state_dim, (1,), buffer_size)\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.network.to(self.device)\n",
    "        self.target_network.to(self.device)\n",
    "\n",
    "        self.total_steps = 0\n",
    "        self.epsilon_decay = (epsilon - epsilon_min) / 1e6\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def act(self, x, training=True):\n",
    "        self.network.train(training)\n",
    "        if training and ((np.random.rand() < self.epsilon) or (self.total_steps < self.warmup_steps)):\n",
    "            a = np.random.randint(0, self.action_dim)\n",
    "        else:\n",
    "            x = torch.from_numpy(x).float().unsqueeze(0).to(self.device)\n",
    "            q = self.network(x)\n",
    "            a = torch.argmax(q).item()\n",
    "        return a\n",
    "\n",
    "    def learn(self):\n",
    "        s, a, r, s_prime, terminated = map(lambda x: x.to(self.device), self.buffer.sample(self.batch_size))\n",
    "        next_q = self.target_network(s_prime).detach()\n",
    "        td_target = r + (1. - terminated) * self.gamma * next_q.max(dim=1, keepdim=True).values\n",
    "        loss = F.mse_loss(self.network(s).gather(1, a.long()), td_target)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        result = {'total_steps': self.total_steps, 'value_loss': loss.item()}\n",
    "        return result\n",
    "\n",
    "    def process(self, transition):\n",
    "        result = {}\n",
    "        self.total_steps += 1\n",
    "        self.buffer.update(*transition)\n",
    "\n",
    "        if self.total_steps > self.warmup_steps:\n",
    "            result = self.learn()\n",
    "\n",
    "        if self.total_steps % self.target_update_interval == 0:\n",
    "            self.target_network.load_state_dict(self.network.state_dict())\n",
    "        self.epsilon = max(self.epsilon_min, self.epsilon - self.epsilon_decay)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdac0302-7953-46e5-8049-d75ef660cb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CarRacing-v2', continuous=False)\n",
    "env = ImageEnv(env)\n",
    "\n",
    "max_steps = int(2e6)\n",
    "eval_interval = 10000\n",
    "state_dim = (4, 84, 84)\n",
    "action_dim = env.action_space.n\n",
    "\n",
    "agent = DQN(state_dim, action_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eb3138-cf30-450e-a761-cccfff1611b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(agent, n_evals=5):\n",
    "    eval_env = gym.make('CarRacing-v2', continuous=False)\n",
    "    eval_env = ImageEnv(eval_env)\n",
    "    scores = 0\n",
    "    for _ in range(n_evals):\n",
    "        s, _ = eval_env.reset()\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        while not terminated and not truncated:\n",
    "            a = agent.act(s, training=False)\n",
    "            s, r, terminated, truncated, info = eval_env.step(a)\n",
    "            scores += r\n",
    "    return scores / n_evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83304d0-e2ce-4cfd-b7e2-e5f4ced7ae98",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns, steps = [], []\n",
    "for step in range(0, max_steps + 1):\n",
    "    s, _ = env.reset()\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "    while not terminated and not truncated:\n",
    "        a = agent.act(s)\n",
    "        s_prime, r, terminated, truncated, info = env.step(a)\n",
    "        terminated = terminated or truncated\n",
    "        result = agent.process((s, [a], [r], s_prime, [terminated]))\n",
    "        s = s_prime\n",
    "\n",
    "        if len(result):\n",
    "            steps.append(result['total_steps'])\n",
    "            returns.append(evaluate(agent))\n",
    "            print(f\"Steps: {result['total_steps']} | Returns: {returns[-1]}\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(steps, returns)\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('return')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7bae68-a3e1-48ac-8c41-9db0311308d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Animation function to save the agent's performance as a video\n",
    "def save_video(agent, filename, n_episodes=1):\n",
    "    frames = []\n",
    "    for _ in range(n_episodes):\n",
    "        s, _ = env.reset()\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        while not terminated and not truncated:\n",
    "            a = agent.act(s, training=False)\n",
    "            s, r, terminated, truncated, info = env.step(a)\n",
    "            frames.append(env.render(mode='rgb_array'))\n",
    "    \n",
    "    height, width, layers = frames[0].shape\n",
    "    video = cv2.VideoWriter(filename, cv2.VideoWriter_fourcc(*'mp4v'), 30, (width, height))\n",
    "    \n",
    "    for frame in frames:\n",
    "        video.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    video.release()\n",
    "    print(f\"Video saved as {filename}\")\n",
    "\n",
    "# Save the trained agent's performance as a video\n",
    "save_video(agent, 'carracing_dqn.mp4', n_episodes=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forklift",
   "language": "python",
   "name": "forklift"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
